# 第62课：宽度优先遍历及其扩展

### 算法题：单词接龙 II (Word Ladder II)

#### 题目描述：

给定两个单词 `beginWord` 和 `endWord`，以及一个字典 `wordList`，你需要找出从 `beginWord` 到 `endWord` 的所有最短转换序列。每次转换只能改变一个字母，并且每个转换后的单词都必须出现在字典 `wordList` 中。

一个有效的转换序列是：`beginWord -> s1 -> s2 -> ... -> sk`，其中每个单词 si （1 <= i <= k）只能通过改变一个字母从前一个单词转换而来，且所有的单词都在 `wordList` 中。

注意：

- `beginWord` 和 `endWord` 不必是 `wordList` 中的单词。
- 每个序列都应该返回为一个单词列表 `[beginWord, s1, s2, ..., sk]` 的形式。
- 如果不存在这样的转换序列，返回一个空列表。

#### 输入：

- `beginWord`：字符串，表示起始单词。
- `endWord`：字符串，表示目标单词。
- `wordList`：一个字符串数组，包含字典中的所有单词。

#### 输出：

- 返回所有从 `beginWord` 到 `endWord` 的最短转换序列。如果没有这样的序列，返回空数组。

#### 示例：

**示例 1**：

```
输入：
beginWord = "hit",
endWord = "cog",
wordList = ["hot", "dot", "dog", "lot", "log", "cog"]

输出：
[
  ["hit","hot","dot","dog","cog"],
  ["hit","hot","lot","log","cog"]
]
```

**示例 2**：

```
输入：
beginWord = "hit",
endWord = "cog",
wordList = ["hot", "dot", "dog", "lot", "log"]

输出：
[]
```

#### 提示：

- 所有单词具有相同的长度。
- `beginWord` 和 `endWord` 是不同的单词。
- `wordList` 中的单词不包含重复的单词。

#### 解法：

- **BFS + DFS**：首先使用广度优先搜索（BFS）来生成从 `beginWord` 到 `endWord` 的最短路径，并记录路径信息。然后使用深度优先搜索（DFS）进行回溯，生成所有可能的最短路径。

#### 思路：

1. **BFS**：从 `beginWord` 开始，逐层扩展所有可能的单词。每次扩展一个字母，检查新生成的单词是否在字典中且未被访问过。如果是，则加入下一层扩展。扩展过程中，记录反向图关系，即每个单词到达的前驱单词。
2. **DFS**：根据 BFS 生成的图，使用深度优先搜索从 `endWord` 回溯到 `beginWord`，生成所有的最短转换路径。

#### 代码实现：

```cpp
#include <vector>
#include <string>
#include <unordered_set>
#include <unordered_map>
#include <queue>
#include <list>
using namespace std;

class Solution {
public:
    unordered_set<string> dict;
    unordered_set<string> curLevel;
    unordered_set<string> nextLevel;
    unordered_map<string, vector<string>> graph;
    list<string> path;
    vector<vector<string>> ans;

    void build(const vector<string>& wordList) {
        dict.clear();
        for (const string& word : wordList) {
            dict.insert(word);
        }
        graph.clear();
        ans.clear();
        curLevel.clear();
        nextLevel.clear();
    }

    vector<vector<string>> findLadders(string beginWord, string endWord, vector<string>& wordList) {
        build(wordList);

        if (dict.find(endWord) == dict.end()) {
            return ans;
        }

        if (bfs(beginWord, endWord)) {
            dfs(endWord, beginWord);
        }

        return ans;
    }

    bool bfs(const string& begin, const string& end) {
        bool find = false;
        curLevel.insert(begin);

        while (!curLevel.empty()) {
            for (const string& word : curLevel) {
                dict.erase(word);  
            }

            for (const string& word : curLevel) {
                string w = word;
                for (int i = 0; i < w.size(); i++) {
                    char old = w[i];
                    for (char ch = 'a'; ch <= 'z'; ch++) {
                        w[i] = ch;
                        if (dict.find(w) != dict.end() && w != word) {
                            if (w == end) {
                                find = true;
                            }
                            graph[w].push_back(word);
                            nextLevel.insert(w);
                        }
                    }
                    w[i] = old;
                }
            }

            if (find) {
                return true;
            } else {
                curLevel.swap(nextLevel);
                nextLevel.clear();
            }
        }

        return false;
    }

    void dfs(const string& word, const string& aim) {
        path.push_front(word);
        if (word == aim) {
            ans.push_back(vector<string>(path.begin(), path.end()));
        } else if (graph.find(word) != graph.end()) {
            for (const string& next : graph[word]) {
                dfs(next, aim);
            }
        }
        path.pop_front();
    }
};
```

#### 时间复杂度：

- **BFS**：每个单词最多被访问一次，对于每个单词，需要对每个字母尝试 26 次，总的时间复杂度是 O(L×N×26)O(L \times N \times 26)，其中 LL 是单词的长度，NN 是字典中单词的数量。
- **DFS**：最坏情况下，我们需要遍历所有的路径，复杂度依赖于路径的数量，假设最短路径的数量为 PP，则 DFS 的复杂度为 O(P×L)O(P \times L)。

#### 空间复杂度：

- 空间复杂度主要来自字典、图、当前层级集合、路径存储等，最坏情况下为 O(N×L)O(N \times L)，其中 NN 是字典的大小，LL 是单词的长度。